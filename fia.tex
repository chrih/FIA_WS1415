\documentclass[a4paper,10pt]{scrreprt}
%\documentclass[a4paper,10pt]{scrartcl}

\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage[pdftex]{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{amssymb}
\usepackage{marvosym}
\usepackage{amsmath}
\usepackage{array}
\usepackage{geometry}
\usepackage{color}

\newcommand{\f}{\noindent\textbf}
\geometry{verbose,tmargin=2cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=3cm,headheight=80pt}

\title{FIA - WS 2014/15}
\author{}
\date{}

\begin{document}
\maketitle

\chapter{Introduction}
\section{Internet}

\begin{itemize}
 \item loosely hierarchical: tier 1 to tier 3
 \item communications infrastructure enables distributed applications
 \item hyper... $\Rightarrow$ concentration of content (Amazon, Google, ...)
\end{itemize}

\section{Protocol Layering}
\begin{itemize}
 \item ISO/OSI
 \item TCP, UDP, ICMP, UDP Like, SCTP, ...
 \item DHCP, NAT, ...
\end{itemize}

\section{Analogue digital conversion}
\begin{itemize}
 \item Fourier transformation 
 \item sampling theorem + Nyquist
 \item PCM-transmission 
 \item small amplitudes are being encoded more detailed than large amplitudes
\end{itemize}

\section{Color Coding}
\begin{itemize}
 \item monochrome, RGB, YCbCr
 \item RGB: 
 \begin{itemize}
  \item red, green, blue values between [0,  \{7,31,...,65535\}]
  \item nonlinear encoding of intensities 
  \item computer graphics
 \end{itemize}
 \item YCbCr
 \begin{itemize}
  \item TV and digital video
  \item Y more important $\Rightarrow$ encode with more details 
  \item more efficient than RGB
  \item can handle downsampling better
  \item YUV is based color model used in analog color TV
  \begin{itemize}
   \item YCbCr is scaled and offset version
   \item YPbPr is the analog version of YCbCr
  \end{itemize}
 \end{itemize}
\end{itemize}

\chapter{Digital coding of audio and video}
\section{Rate-Distortion Theory}
\begin{itemize}
 \item lossless compression algorithms 
 \begin{itemize}
  \item allow perfect reconstruction 
  \item low compression ratios
  \item frequently encountered data is encoded more efficiently 
 \end{itemize}
 \item lossy compression algorithms
 \begin{itemize}
  \item result is only a close approximation of original data
  \item trade-off: distortion vs. required rate 
  \item much higher compression rate than lossless compression
 \end{itemize}
//TODO: bild einfuegen
 \item rate and distortion as measures for efficiency of compression and difference between reconstructed and original data 
 \begin{itemize}
  \item goal is to minimize distortion and rate 
  \item basic problem:
  \begin{itemize}
   \item minimum expected distortion at a given rate?
   \item minimum rate to achieve given distortion?  
  \end{itemize}
 \end{itemize}
 \item distortion measures
 \begin{itemize}
  \item mean square error $\sigma^2 = \frac{1}{N}\sum\limits_{i=1}^N(x_i - y_i)^2$
  \item signal to noise ratio $SNR = 10 log_{10}\frac{\sigma_x^2}{\sigma_d^2}$
  \item peak signal to noise ratio $PSNR = 10 log_{10}\frac{x_{peak}^2}{x_d^2}$
 \end{itemize}
 \item in order to maximize efficient communication maximize mutual information between x and y 
 \item rate distortion function 
\end{itemize}

\section{digital image}
\begin{itemize}
 \item conversion between RGB and YUV
 \item downsampling J:a:b
 \begin{itemize}
  \item 4:4:4 $\widehat{=}$ no downsampling
  \item 4:2:2 $\widehat{=}$ 
  \item 4:2:0 $\widehat{=}$ 
 \end{itemize}
 \item statistical image modeling 
 \begin{itemize}
  \item all natural images occupy a tiny and unknown sloped space of all images 
  \item pixel intensities are dependent and correlated to the corresponding image $\Rightarrow$ pixel within images are highly correlated 
  \item correlation of pixels has high impact on image compression
 \end{itemize}
 \item image transformations 
 \begin{itemize}
  \item negative transformations
  \item log transformations
  \item power-law transformations
 \end{itemize}
 \item intensity:
 \begin{itemize}
  \item change in brightness $\Rightarrow$ shift of histogram
  \item change in contrast $\Rightarrow$ stretch/? of histogram
 \end{itemize}
\item filters based on convolution of neighbor pixels $\Rightarrow$ enhancement, smoothing, edge, detection, ...
\item the hoar transform 
\begin{itemize}
 \item simplest useful energy compression
 \item lossless retransformation is possible 
 \item transform original image into 4 parts (in 20)
 \begin{enumerate}
  \item top-left: a+b+c+d, 4 point average, very important
  \item top-right: a-b+c-d, average horizontal gradient, less important
  \item bottom-left: a+b-c-d, average vertical gradient, less important
  \item bottom-right: a-b-c+d, diagonal curvature, less important
 \end{enumerate}
 \item 1 is more expensive while 2-4 is cheaper to encode 
 \item reordering required to provide ``typical'' representation
\end{itemize}
 \item entropy -- quantifying the required bitrate
 \begin{itemize}
  \item entropy $H_x$ represents the mean number of bits per pixel that are required to encode the image 
  \item $H_x = \sum\limits_{i=0}^{M-1} p_i-log_2\left(\frac{1}{p_i}\right)$ where $p_i = \frac{\text{pixel in bin i}}{N}$ where N is the number of pixels
  \item estimated number of bits needed is $H_x\cdot N$
 \end{itemize}
 \item the Karkunen-Loeve transform (KLT)
 \begin{itemize}
  \item is optimal for minimizing bitrate
  \item not or seldom used in practice $\Rightarrow$ slow and complex
 \end{itemize}
 \item the discrete cosine transformation (DCT)
 \begin{itemize}
  \item seems to put most energy on a small number of values
  \item linear transformation
  \item each real world image can be represented by a combination of the DCT bases
  \item DCT bases fit better to typical images than FFT or DST
  \item first coefficient of DCT is mean of values being transformed and represents average tone of the block. subsequent blocks add further detail
  \item JPEG: $8\times 8$ DCT (empirically found to be good)
 \end{itemize}
 \item need for wavelets
 \begin{itemize}
  \item signals are available in time-domain but processing frequency information is much more easy
  \item transformations (e.g. FFT) translate time-domain signals into frequency domains
  \begin{itemize}
   \item useful for stationary signals where all frequencies are present at all times
   \item not useful for instationary signals: both information required
   \item solution: short term transformation---transformation of small fixed timewindows (similar to blocks of images)
  \end{itemize}
  \item wavelet analysis uses different sized windows
  \begin{itemize}
   \item high frequency parts $\Rightarrow$ small windows $\Rightarrow$ good time resolution
   \item low frequency parts $\Rightarrow$ big windows $\Rightarrow$ good frequency resolution
  \end{itemize}
 \end{itemize}
\end{itemize}
\section{JPEG compression}
\begin{itemize}
 \item joint photographic experts groups
 \item \includegraphics[width=.8\linewidth]{jpeg.jpg}
\end{itemize}
\section{digital video}
\begin{itemize}
 \item high corellation between successive frames
 \item interframe differential pulse code modulation ($\Rightarrow$ vgl. skript skizze)
 \item frame replenishment $\Rightarrow$ pixels are only transmitted if a specified threshold is exceeded, otherwise nothing is transmitted
 \item change detection
 \begin{itemize}
  \item pixel wise change detector
  \item block wise change detector
  \item comparison between current and previous frame
  \begin{itemize}
   \item substract previous frame from current one
   \item convert to absolute value
   \item generate $3\times 3$ averages
   \item check for threshold
  \end{itemize}
 \end{itemize}
 \item motion compensated coding 
 \begin{itemize}
  \item changes between frames due to moving objects $\Rightarrow$ estimation of motion vectors
  \item prediction and original frame may differ significantly
  \begin{itemize}
   \item solution: compute and transmit prediction error additionally
   \item higher coding efficiency but also higher computational complexity
  \end{itemize}
  \item three-stage-coding:
  \[ \text{Motion Analysis} \Rightarrow \text{Prediction and differentiation} \Rightarrow \text{Encoding} \]
 \end{itemize}
 \item block matching
 \begin{itemize}
  \item partitioning of frame into nonoverlapping equally spaced and fixed size rectangular blocks
  \item smaller block size $\Rightarrow$ better approximation but higher computational complexity
  \item $16 \times 16 $ blocks used in MPEG-1 and -2
  \item calculate best displacement vector for each block
  \item search strategies:
  \begin{itemize}
   \item full search
   \item 2D logarithmic search
   \item diamond search
  \end{itemize}
 \end{itemize}
\item grouping of elements
  \begin{itemize}
   \item sequence $\rightarrow$ frame $\rightarrow$ slice $\rightarrow$ macroblock $\rightarrow$ block $\rightarrow$ pixel
  \end{itemize}
 \item different frame types 
 \begin{itemize}
  \item I-frame: intra-coded-frame: independent of other frames 
  \item P-frame: predictively coded frame: depends on previous frame 
  \item B-frame: bidirectionally predicted frame: depends on previous and subsequent frames 
 \end{itemize}
 \item scalable video encoding -- H.264/SVC
 \begin{itemize}
  \item different frame rates
  \item different resolutions
  \item variable image quality 
  \item layered video codec (LVC)
  \begin{itemize}
   \item base layer is encoded in H.264/SVC
   \item enhancement layers allow refinement of base quality 
   \item different combinations of temporal, spatial and quality refinement is possible
   \\ TODO: Bild einfuegen
   \item refinement is represented by 3D cube of cubes 
  \end{itemize}
 \item temporal scalability: adding B-frames to the base layer 
 \item spatial scalability: 3 mechanisms
 \begin{itemize}
  \item interlayer prediction 
  \item residual prediction
  \item motion prediction 
 \end{itemize}
 \item quality scalability
 \begin{itemize}
  \item interlayer prediction (like in spatial scaling)
  \item up sampling
  \item different quantization parameters
 \end{itemize}
 \item idea is to adept the video quality to the available bandwidth by removing or adding enhancement layers 
 \end{itemize}
\item network abstraction layer (NAL)
\begin{itemize}
 \item frames are packaged in NAL units 
 \begin{itemize}
  \item payload of 1 package is one layer of one frame 
  \item layers are separated into different streams
  \item MANE (media aware network element)
  \begin{itemize}
   \item decides package forwarding
   \item separate layers on separate flows (???) allow adapted forwarding 
  \end{itemize}
 \end{itemize}
\end{itemize}
\item use of LVC and NAL
\begin{itemize}
 \item adaption in case of device or network limitations 
 \item reduce storage size by removing enhancement layers 
 \item video broadcasting: base layer free + payed enhancement
\end{itemize}
\item multi description coding 
\begin{itemize}
 \item n frames/s using 1 description 
 \item 2n frames/s using 2 description
 \item 2 alternatives 
 \begin{enumerate}
  \item independent description: robust + inefficient 
  \item $\rightarrow$ less robust + more efficient 
 \end{enumerate}
 \item robust against package loss 
\end{itemize}
\item comparison of different video codings
\begin{itemize}
 \item layered $>$ MDC2 $>$ MDC1 
 \item non variable coding is most efficient but not adaptive to changes in network limit or device limitations
\end{itemize}
\end{itemize}

\section{Estimating quality of media applications}
\begin{itemize}
 \item what is QoE? 
 \begin{itemize}
  \item the overall acceptability of an application or service as perceived subjectively by the end user
  \item definition is still evolving
  \item closely related to QoS
  \item QoE is usually a subjective value 
  \item assessed by asking or observing users 
 \end{itemize}
 \begin{itemize}
 \item related values: 
 \begin{itemize}
  \item quality of presentation, quality of delivery 
  \item hourglass model matches QoX with layers of the ISO/OSI model 
  \item QoS $\rightarrow$ QoD $\rightarrow$ QoP $\rightarrow$ QoE 
 \end{itemize}
 \item often characterized with MOS (mean opinion score)
\end{itemize}
\item QoE assessment methods and tools 
\begin{itemize}
 \item subjective QoE 
 \begin{itemize}
  \item ask or observe the user (use questionaires, rating scales, annotations)
 \end{itemize}
 \item mean opinion score 
 \begin{itemize}
  \item widely used (politics, marketing, ...)
  \item the likely level of satisfaction of a service or product as appreciated by an average user
  \item average might be resulting by two extremes 
  \item use discrete scales and an odd number of steps
 \end{itemize}
\end{itemize}
\item subjective tests are often expensive and time consuming
\begin{itemize}
 \item objective algorithms are desired (MOS predictors)
 \begin{itemize}
  \item MSE (bad) $\Rightarrow$ doesn't care about reordering
  \item PSNR $\Rightarrow$ correlation of c.a. 80 \% to subjective studies (but sometimes much worse)
  \item maximum pixel deviation
  \item multiscale structural similarity (MSSIM) $\Rightarrow$ very good
 \end{itemize}
\end{itemize}
\item region of interest $\Rightarrow$ salient vs. non-salient regions (e.g. football)
\end{itemize}
\chapter{data communication and transport protocol}
\begin{itemize}
 \item connection-oriented:
 \begin{itemize}
  \item setting up a call and release the call afterwards (TCP)
 \end{itemize}
 \item connection-less:
 \begin{itemize}
  \item packet switching without call establishment
 \end{itemize}
\end{itemize}
\section{single path transport protocol}
\begin{itemize}
 \item UDP and UDP-lite
 \begin{itemize}
  \item SRC part $\|$ DST part $\|$ length $\|$ checksum $\|$ data 
  \begin{itemize}
   \item suiteable for real-time applications (nondelayed transmission)
   \item works well for broadcasting (e.g. service discovery, video broadcast)
  \end{itemize}
  \item UDP-like replaces length with checksum coverage
  \item UDP-like headers must be protected by the checksum
 \end{itemize}
 \item TCP basics
 \begin{itemize}
  \item SYN and ACK flags
  \item sequence numbers: number of packet ascending
  \item acknowledgement number: if ACK is set, this is the next sequence the reciever expects
  \item connection establishment (3-way-handshake)
  \begin{itemize}
   \item client sends SYN with random sequence number $A$
   \item server responds ACK with acknowledgement number $A+1$ and random sequence number $B$
   \item client sends ACK with acknowledgement number $B+1$ and sequence number $A+1$
   \item result: full duplex connection
  \end{itemize}
  \item key features of TCP
  \begin{itemize}
   \item orders data transfer
   \item retransmission
   \item error free data transfer
   \item flow control
   \item congestion control
  \end{itemize}
  \item TCP measures round-trip-time (RTT) and calculates expected RTT for future packets
 \end{itemize}
 \item compound TCP
 \begin{itemize}
  \item combines delay-based and loss-based congestion control
  \item higher throughput than normal TCP at high RTT
 \end{itemize}
 \item cubic TCP
 \begin{itemize}
  \item \includegraphics[width=.8\linewidth]{cubictcp.jpg}
  \item fair for low RTT, very aggressive for high RTT
 \end{itemize}
 \item RED -- random early detection
 \begin{itemize}
  \item schedulers for congestion avoidance
  \item idea: monitor average queue size and drop packets based on statistical probabilities
  \item problems: has strong impact on TCP (retransmission)
 \end{itemize}
 \item ECN -- explicit congestion notification
 \begin{itemize}
  \item allows end-to-end notifications of network congestion without dropping packets
  \item ECN-routers may set a mark in the TCP headers to signal impending congestion to the reciever. the reciever echos a signal to the sender which then can reduce transmission rates
  \item can reduce the number of dropped packets
  \item may reduce performance on highly congested networks
 \end{itemize}
 \item DCCP -- congestion control without reliability
 \begin{itemize}
  \item TCP: long living flows to guarantee fairness
  \item UDP: short living flows and multicast applications
  \item problem: UDP is used for long-living flows with live constraints: streaming, VoIP, online-gaming $\Rightarrow$ no congestion controll using UDP may result in congestion collapse of the internet
  \item requirements: 
  \begin{itemize}
   \item choice of congestion controll mechanisms
   \item low per-packet overhead
   \item ECN support
   \item middlebox traversal (NAT/Firewall)
  \end{itemize}
  \item congestion controll mechanisms
  \begin{itemize}
   \item TCP-like: congestion controll
   \item TCP-friendly: congestion controll
  \end{itemize}
  \item SCTP -- stream controll transmission protocol
  \begin{itemize}
   \item properties:
   \begin{itemize}
    \item security: 4-way-handshake
    \item resilience: multi-homing, crc32--checksum
    \item practical features: 
    \begin{itemize}
     \item IPv4 and IPv6 simultaneously
     \item multi-streaming
     \item message-oriental
    \end{itemize}
    \item support extensions
   \end{itemize}
   \item multi-homing
   \begin{itemize}
    \item SCTP associates two nodes (connection)
    \item if primary path between nodes breaks connection switches to another path
   \end{itemize}
   \item multi-streaming (vgl. script 3.49)
 \end{itemize}
 \end{itemize}
 \section{multi-path transport protocols}
 \begin{itemize}
  \item multi-path TCP: split data transmission via multiple paths
  \begin{itemize}
   \item enhances reliability and flexibility
   \item allows balancing of data transmission via links with different limitations
   \item common problem: out-of-order arrival
  \end{itemize}
 \end{itemize}
\end{itemize}
\end{document}
